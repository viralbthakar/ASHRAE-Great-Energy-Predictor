{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual Model Development for Energy Consumption Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score, mean_squared_log_error\n",
    "\n",
    "from utils import styled_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather('../data/x_train.ftr')\n",
    "validation_df = pd.read_feather('../data/x_validation.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_print(\"Training Dataset Summary\", header=True)\n",
    "styled_print(f\"The shape of train_df is {train_df.shape}\")\n",
    "styled_print(f\"The columns in train_df are {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_print(\"Validation Dataset Summary\", header=True)\n",
    "styled_print(f\"The shape of validation_df is {validation_df.shape}\")\n",
    "styled_print(f\"The columns in validation_df are {list(validation_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_desc=\"ASHRAE Model\", antilog=True):\n",
    "    if antilog:\n",
    "        y_true = np.exp(y_true)\n",
    "        y_pred = np.exp(y_pred)\n",
    "        rmsle = math.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    else:\n",
    "        mlse = mean_squared_error(y_true, y_pred)\n",
    "        rmsle = math.sqrt(mlse)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    styled_print(f\"Evaluation of {model_desc}\", header=True)\n",
    "    styled_print(f\"R2 Score: {r2}\")\n",
    "    styled_print(f\"Mean Absolute Error: {mae}\")\n",
    "    styled_print(f\"Mean Absolute Percentage Error: {mape}\")\n",
    "    styled_print(f\"Root Mean Square Logarithmic Error: {rmsle}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first step we create a baseline model, where we predict the `mean` value based on group by `primary_use` and `meter_type`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_baseline = train_df.groupby(['primary_use', 'meter_type'])['log_meter_reading'].mean().reset_index()\n",
    "y_pred_baseline.rename(columns={\"log_meter_reading\": \"y_pred_baseline\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_df = train_df.copy()\n",
    "temp_validation_df = validation_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_df = temp_train_df.merge(y_pred_baseline, on=['primary_use', 'meter_type'], how='left')\n",
    "temp_validation_df = temp_validation_df.merge(y_pred_baseline, on=['primary_use', 'meter_type'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    temp_train_df['log_meter_reading'], \n",
    "    temp_train_df['y_pred_baseline'], \n",
    "    model_desc=\"Baseline Model - Training Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    temp_validation_df['log_meter_reading'], \n",
    "    temp_validation_df['y_pred_baseline'], \n",
    "    model_desc=\"Baseline Model - Validation Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected our baseline model does very poor on training and validation set. Let's try Decision Tree model as next step. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['log_meter_reading']\n",
    "y_validation = validation_df['log_meter_reading']\n",
    "\n",
    "x_train = train_df.drop(['log_meter_reading', 'index'], axis=1)\n",
    "x_validation = validation_df.drop(['log_meter_reading', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_use_enc = LabelEncoder().fit(x_train['primary_use'])\n",
    "season_enc = LabelEncoder().fit(x_train['season'])\n",
    "meter_type_enc = LabelEncoder().fit(x_train['meter_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['season'] = season_enc.transform(x_train['season'])\n",
    "x_validation['season'] = season_enc.transform(x_validation['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['primary_use'] = primary_use_enc.transform(x_train['primary_use'])\n",
    "x_validation['primary_use'] = primary_use_enc.transform(x_validation['primary_use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['meter_type'] = meter_type_enc.transform(x_train['meter_type'])\n",
    "x_validation['meter_type'] = meter_type_enc.transform(x_validation['meter_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = pd.DataFrame(scaler.transform(x_train), columns = x_train.columns)\n",
    "x_validation = pd.DataFrame(scaler.transform(x_validation), columns = x_validation.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decision tree classifier object\n",
    "dt_reg = DecisionTreeRegressor()\n",
    "\n",
    "# Define the hyperparameter grid for the decision tree\n",
    "# params = {\n",
    "#     'max_depth': [4, 5, 6, 7, 8, 9, 10, 15, None],\n",
    "#     'min_samples_split': [2, 3, 4],\n",
    "#     'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'max_depth': [15]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the training data\n",
    "grid_search = GridSearchCV(estimator=dt_reg, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validated score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred_train = best_model.predict(x_train)\n",
    "y_pred_validation = best_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    y_train, y_pred_train, \n",
    "    model_desc=\"Decision Tree - Training Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    y_validation, y_pred_validation, \n",
    "    model_desc=\"Decision Tree - Validation Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [3, 5, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rfc = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(rfc, params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validated score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred_train = best_model.predict(x_train)\n",
    "y_pred_validation = best_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    y_train, y_pred_train, \n",
    "    model_desc=\"Random Forest - Training Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    y_validation, y_pred_validation, \n",
    "    model_desc=\"Random Forest - Validation Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search over\n",
    "params = {\n",
    "    \"learning_rate\": [0.01, 0.1, 1],\n",
    "    \"n_estimators\": [100, 500, 1000],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "}\n",
    "\n",
    "# Create a gradient boosting regressor\n",
    "gb_regressor = GradientBoostingRegressor()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(gb_regressor, params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validated score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred_train = best_model.predict(x_train)\n",
    "y_pred_validation = best_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    y_train, y_pred_train, \n",
    "    model_desc=\"Gradient Boosted Machines - Training Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    y_validation, y_pred_validation, \n",
    "    model_desc=\"Gradient Boosted Machines - Validation Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential\n",
    "\n",
    "# Define the model function\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "# Create the KerasRegressor model\n",
    "model = KerasRegressor(build_fn=create_model)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "parameters = {\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [50, 100],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# Train the model using GridSearchCV\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validated score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred_train = best_model.predict(x_train)\n",
    "y_pred_validation = best_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    y_train, y_pred_train, \n",
    "    model_desc=\"Neural Networks - Training Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\n",
    "    y_validation, y_pred_validation, \n",
    "    model_desc=\"Neural Networks - Validation Set\",\n",
    "    antilog=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asharae-energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
